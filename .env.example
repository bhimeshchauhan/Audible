# =============================================================================
# PDF Character Graph - Environment Configuration
# =============================================================================
# Copy this file to .env and customize as needed.
# All values shown are defaults.

# =============================================================================
# Server Configuration
# =============================================================================
# Host and port for the backend server
SERVER_HOST=127.0.0.1
SERVER_PORT=8000
SERVER_RELOAD=false
SERVER_WORKERS=1

# Environment mode (development, production)
ENVIRONMENT=development
DEBUG=false

# =============================================================================
# CORS Configuration
# =============================================================================
# Comma-separated list of allowed origins
# For production, set this to your frontend domain(s)
CORS_ORIGINS=http://localhost:3000,http://localhost:5173
CORS_CREDENTIALS=true
CORS_METHODS=GET,POST,OPTIONS
CORS_HEADERS=*

# =============================================================================
# File Upload Configuration
# =============================================================================
# Maximum upload size in MB
UPLOAD_MAX_SIZE_MB=50
# Optional: custom temp directory for uploads
# UPLOAD_TEMP_DIR=/tmp/pdf-uploads

# =============================================================================
# LLM Configuration
# =============================================================================
# Use local Ollama (true) or OpenAI cloud (false)
USE_LOCAL_LLM=true

# --- Local (Ollama) Settings ---
LOCAL_MODEL=llama3.2
LOCAL_BASE_URL=http://localhost:11434/v1

# --- Cloud (OpenAI) Settings ---
# Required if USE_LOCAL_LLM=false
# OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o-mini

# LLM request settings
LLM_TEMPERATURE=0.0
LLM_MAX_WORKERS=2
LLM_MIN_REQUEST_INTERVAL_SEC=0.1
LLM_MAX_RETRIES=3

# =============================================================================
# NLP Processing Configuration
# =============================================================================
# spaCy model to use
SPACY_MODEL=en_core_web_sm

# Enable coreference resolution (requires more memory)
ENABLE_COREF=true
COREF_MODEL_ARCH=FCoref

# Maximum pages to process (leave empty for all)
# MAX_PAGES=100

# Text segmentation
MIN_SENTENCE_LEN=10
WINDOW_SENTENCES=8
WINDOW_STRIDE=4
MAX_CONTEXT_CHARS=1600

# Character extraction
MIN_PERSON_FREQ=2
MAX_PEOPLE_PER_WINDOW=10

# Relationship extraction
MIN_INTERACTION_WEIGHT=2
EVIDENCE_PER_PAIR=6
MAX_PAIRS_TO_DESCRIBE=400

# Quote verification
MIN_QUOTE_WORDS=5
MAX_QUOTE_WORDS=40
REQUIRE_QUOTES=true

# Output directory for CLI usage
OUTPUT_DIR=results
